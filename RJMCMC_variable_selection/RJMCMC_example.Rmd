---
title: "Reversible Jump MCMC"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
  fig.align = "center")
```

Reversible Jump MCMC (RJMCMC) is a method for sampling across models with a different numbers of dimensions, which finds natural application in Bayesian variable selection problems.  In this setting, RJMCMC requires a proposal distribution for the coefficient of a variable when the variable is proposed to be included in the model.
NIMBLE uses a univariate normal proposal distribution. 

There are two ways to use RJMCMC variable selection in your model.  If you know the prior probability for inclusion of a variable in the model, you can use that directly in RJMCMC without modifying your model.  If you need the prior probability for inclusion in the model to be a model node itself, such as if it will have a prior and be estimated, you will need to write the model with indicator variables.  The latter is more flexible and is illustrated in the example below.

More information can be found in the user manual and via `help(configureRJ)`.

## Linear regression example

For simplicity we consider a linear regression example with $15$ explanatory variables, of which $5$ have real effects. The other 10 have null effects, i.e. the corresponding coefficient is equal to $0$.

```{r load_nimble}
library(nimble, warn.conflicts = FALSE)
```

```{r nimble_model}
lmCode <- nimbleCode({
  sigma ~ dunif(0, 20)
  psi ~ dunif(0,1)   ## prior on inclusion probability
  
  for(i in 1:numVars) {
    z[i] ~ dbern(psi) ## indicator variable for each coefficient
    beta[i] ~ dnorm(0, sd = 100)  
    zbeta[i] <- z[i] * beta[i]  ## indicator * beta
  }
  for(i in 1:n) {
    pred.y[i] <- inprod(X[i, 1:numVars], zbeta[1:numVars])
    y[i] ~ dnorm(pred.y[i], sd = sigma)
  }
})
## Generate data and define model constants
set.seed(1)
numVars = 15
n = 100
## Simulate explanatory variables
X <- matrix(rnorm(n*numVars), nrow = n, ncol = numVars)
lmConstants <- list(numVars = numVars, n = n, X = X)
lmModel <- nimbleModel(lmCode, constants = lmConstants)
```

We can simulate data using the `nimbleModel` we just created by initializing the model parameters and calling the `simulate()` method. 

```{r simulate_data, message = F}
## Set the first give coefficients to be non-zero and the remaining
## ones to be zero.
true_betas <- c(c(0.1, 0.2, 0.3, 0.4, 0.5),
                rep(0, 10))

lmModel$beta <- true_betas
lmModel$sigma <- 1
lmModel$z <- rep(1, 15)
lmModel$psi <- 0.5
this_will_be_NA <- lmModel$calculate() ## Update nodes that depend on values we just set..
set.seed(0) ## Make this example reproducible
lmModel$simulate('y') ## Simulate y
lmModel$calculate() ## Update calculations
lmModel$setData('y') ## Mark the simulated y values as data
lmData = list(y = lmModel$y) ## Record the simulated y values for use below
```

<!-- For comparison we look first to simple linear regression:

```{r use_lm}
summary(lm(lmModel$y ~ lmModel$X))
```
 -->

## Configuring RJMCMC

The RJCMCM sampler can be added to the MCMC configuration by calling the function `configureRJ()`. In this example, `z` are indicator variables associated with the coefficients `beta`. We pass them to `configureRJ` using the arguments `indicatorNodes` and `targetNodes`. The `control` argument allows us to specify the mean and the scale of the normal proposal distribution. 

```{r configure_RJ}
lmConf <- configureMCMC(lmModel)
lmConf$addMonitors('z')
configureRJ(lmConf,
            targetNodes = 'beta',
            indicatorNodes = 'z',
            control = list(mean = 0, scale = .2))
```


Checking the assigned samplers, we can see that indicator parameters are assigned to an `RJ_indicator` sampler whose `targetNode` is the corresponding coefficient, while `beta` parameters are assigned to a `RJ_toggled` sampler, which is used only when its target parameter is included in the model.

```{r }
## Check the assigned samplers
lmConf$printSamplers(c("z[1]", "beta[1]"))

```

## Build and run the RJMCMC

```{r build_run_model}
mcmcRJ <- buildMCMC(lmConf)

cLmModel <- compileNimble(lmModel)
CMCMCRJ <- compileNimble(mcmcRJ, project = lmModel)
set.seed(100)
system.time(samplesRJ <- runMCMC(CMCMCRJ, niter = 100000, nburnin = 10000, thin = 10))
```

## Look at the results
<!-- post-processing : variables probabilities, model probabilities -->

For each variable we can look at the sampled values of the indicator and corresponding coefficient.

```{r, fig.align = "center"}
plot(samplesRJ[,'z[5]'], pch = '.', main = "z[5] traceplot")
plot(samplesRJ[,'beta[5]'], pch = '.', main = "beta[5] traceplot")
```

### Posterior inclusion probability, `psi`

Here is the posterior density of inclusion probability.

```{r}
plot(density(samplesRJ[,'psi']), main = "Inclusion probability", xlab = "Probability", ylab = "Density")
```

### Individual inclusion probabilities

Here are the marginal probabilities of inclusion for each variable.

```{r}
zNames <- lmModel$expandNodeNames('z')
zCols <- which(colnames(samplesRJ) %in% zNames)
posterior_inclusion_prob <- colMeans(samplesRJ[,zCols])
plot(1:length(true_betas), posterior_inclusion_prob,
  xaxt = 'none', 
	xlab = "beta", ylab = "Inclusion probability", 
	main = "Inclusion probabilities for each beta")
axis(1, seq(0,15,1))
```

### Model probabilities

Finally we can look at the posterior probabilities for every model that was explored by the MCMC, coded by the vector of indicator variables `z`.

```{r, message = F, warning = F}
library(data.table)

binary <- as.data.table((samplesRJ[, zCols] != 0)+ 0)
res <- binary[,.N, by=names(binary)]
res <-res[order(N, decreasing = T)]
res <- res[, prob := N/dim(samplesRJ)[1]]
  
res[1:5, ]

```

<!-- Alternative in base R

nSamples <- dim(samplesRJ)[1]
binary <- as.data.frame((samplesRJ[, zCols] != 0)+ 0)
res <- binary[,.N, by=names(binary)]
dd <- table(do.call(paste, binary))
(sort(dd, decreasing = T)/nSamples)[1:5]
 -->