# This file was generated by purl("AFT_comparison.Rmd") and then
# edited with additional comments.
# Where code is commented, that means it was set to "eval=FALSE" in the Rmd file.
# It can be uncommented and run.

## ----setup, include=FALSE-----------------------------------------------------
knitr::opts_chunk$set(echo = TRUE)


## ---- results='hide'----------------------------------------------------------
# From BFG:
# Load packages:
library(coda)
library(tictoc)
library(mvtnorm)

# Nimble 
library(nimble) 

## Re-organize BFG's simulation code into a function, and include a `set.seed` for reproducibility.
## ----eval=FALSE---------------------------------------------------------------
## # Here is code for model simulation taken from BFG and placed into a function
## 
## #MODEL: AFT, non-hierarchical prior
## #SIMULATION OF DATA of JAGS and NIMBLE
## simulate_AFT_case <- function(N = 1000, p = 16, perc = 0.8, seed = 0) {
##   set.seed(seed) # Make it reproducible
##   # N is the number of elements in the dataset
##   #
##   # simulate covariates
##   # p is the number of covariates
##   # p <- 16
##   X<-matrix(nrow=N, ncol=p)
##   X[,1]<-rep(1,N) # intercept
##   for(i in 2:p){
##     X[,i] <- rnorm(n = N, mean = 0 , sd =1 ) #
##   }
##   # true parameters
##   beta <- runif(p,min=-1,max=1)
##   mu <- X %*% beta
##   sigma <- 1
##   #for repeated simulations
##   sigma <- runif(1, min = 1, max = 5)
##   alpha <- 1/sigma
##   lambda <- exp(mu)/((log(2))^(1/alpha)) #attenzione alle diverse parametrizzazione della weibull
##   # perc=0.8 #Percentuale dati censurati. Oppure 0.5 o 0.8
##   #perc=runif(1, min = 0.2, max = 0.8) #simulazioni ripetute
##   theta=(1/perc-1)^(1/alpha)*lambda
## 
##   survt = rweibull(N, shape=alpha, scale = lambda) #t_i.  BFG label this t in some places and survt in others.
##   cent = rweibull(N, shape=alpha, scale = theta) #c_i
## 
##   list(X = X,
##        survt = survt,
##        cent = cent,
##        p = p,
##        N = N,
##        beta = beta,
##        alpha = alpha)
## }

## Set up a list of cases that match those of BFG.
## These are listed out for easy reading.  Each has a different seed so that simulated coefficients and covariates will not be subsets from one case to another.

## ----eval=FALSE---------------------------------------------------------------
## cases <- list()
## # Cases with expected fraction of censored data = 0.2
## cases[["N=100, p = 4, perc = 0.2"]]   <- simulate_AFT_case(N = 100 , p = 4, perc = 0.2, seed = 1)
## cases[["N=1000, p = 4, perc = 0.2"]]  <- simulate_AFT_case(N = 1000, p = 4, perc = 0.2, seed = 2)
## cases[["N=100, p = 16, perc = 0.2"]]  <- simulate_AFT_case(N = 100 , p = 16, perc = 0.2, seed = 3)
## cases[["N=1000, p = 16, perc = 0.2"]] <- simulate_AFT_case(N = 1000, p = 16, perc = 0.2, seed = 4)
## 
## # Cases with expected fraction of censored data = 0.5
## cases[["N=100, p = 4, perc = 0.5"]]   <- simulate_AFT_case(N = 100 , p = 4, perc = 0.5, seed = 5)
## cases[["N=1000, p = 4, perc = 0.5"]]  <- simulate_AFT_case(N = 1000, p = 4, perc = 0.5, seed = 6)
## cases[["N=100, p = 16, perc = 0.5"]]  <- simulate_AFT_case(N = 100 , p = 16, perc = 0.5, seed = 7)
## cases[["N=1000, p = 16, perc = 0.5"]] <- simulate_AFT_case(N = 1000, p = 16, perc = 0.5, seed = 8)
## 
## # Cases with expected fraction of censored data = 0.8
## cases[["N=100, p = 4, perc = 0.8"]]   <- simulate_AFT_case(N = 100 , p = 4, perc = 0.8, seed = 9)
## cases[["N=1000, p = 4, perc = 0.8"]]  <- simulate_AFT_case(N = 1000, p = 4, perc = 0.8, seed = 10)
## cases[["N=100, p = 16, perc = 0.8"]]  <- simulate_AFT_case(N = 100 , p = 16, perc = 0.8, seed = 11)
## cases[["N=1000, p = 16, perc = 0.8"]] <- simulate_AFT_case(N = 1000, p = 16, perc = 0.8, seed = 12)
## 
## save(cases, file = "cases.RData")


##### Set up model code in NIMBLE's dialect of the BUGS language.
## The `use_informative_priors` allows the same code to be used to choose BFG's settings for informative priors or uninformative priors.  We only look at the former here.
## ---- eval=FALSE--------------------------------------------------------------
## #NIMBLE
## use_informative_priors <- TRUE
## 
## AFT_NH_Code <- nimbleCode({
##   #Likelihood
##   for(i in 1:N){
##     for(s in 1:p){
##       a[i,s] <- X[i,s]*(beta[s])
##     }
##     mu[i] <- sum(a[i,])
##     lambda[i] <- log(2)*exp(-mu[i]*alpha)
##     censured[i] ~ dinterval(t[i], cent[i])
##     t[i] ~ dweib(alpha, lambda[i])
##   }
##   #Priors
##   if(use_informative_priors) {
##     for(i in 1:p){
##       beta[i] ~ dnorm(0,sd=sqrt(10))
##     }
##     alpha ~ dexp(1)
##   } else {
##     for(i in 1:p){
##       beta[i] ~ dnorm(0, var=1000)
##     }
##     alpha ~ dunif(0.01, 100)
##   }
## })


## Take BFG's code for running NIMBLE, generalize it a bit, and put it in a function.

## We added options to set up valid initial values and to use slice sampling on all variables.  Other configurations could potentially be more efficient but only this simple step was explored.

## ---- eval=FALSE--------------------------------------------------------------
## run_nimble_bfg <- function(code, data, set_t_inits = FALSE, use_slice = FALSE) {
##   attach(data)
##   on.exit(detach(data))
##   t <- survt
##   censured=t>cent # censured = censored
##   delta <- as.logical(1-censured)
##   t[censured==1]=NA
##   cent[censured==0]=Inf
##   beta0=rep(0.1, p)
##   alpha0=0.1
## 
##   aftConsts <- list(N=N,p=p)
##   aftInits <-  list(beta=beta0,alpha=alpha0)
##   aftData <- list(X=X,cent=cent,t=t,censured=censured)
## 
##   if(set_t_inits) {
##     aftInits$t <- t
##     aftInits$t[censured==1] <- cent[censured==1]*1.05
##     aftInits$t[censured==0] <- NA
##   }
## 
##   t1<- system.time(
##     {
##       aftNH <- nimbleModel(code = code,dimensions = list(a = c(N,p)),
##                            name = "aftNH",constants = aftConsts, data = aftData, inits = aftInits)
##       Caft <- compileNimble(aftNH)
##       aftConf <- configureMCMC(aftNH, print = TRUE, onlySlice = use_slice)
##       aftConf$addMonitors(c("beta","alpha","t"))
##       aftMCMC <- buildMCMC(aftConf)
##       CaftMCMC <- compileNimble(aftMCMC, project = aftNH)
##       t2<- system.time(
##         {
##           Psamples <- runMCMC(CaftMCMC, niter=(10000), nburnin=5000, thin=2,
##                               nchains=1,samplesAsCodaMCMC = TRUE,summary=TRUE)
##         })
##     })
##   list(t1 = t1, t2 = t2, Psamples = Psamples)
## }

## Generate BFG-style (**invalid**) results for all cases. 

## We include this so we can try to roughly compare performance improvements below against what they report.  However one difficulty is that processing with `-Inf` and `NaN` values can be substantially slower than processing with actual numbers, and these issues might differ across systems.

## ----eval=FALSE---------------------------------------------------------------
## load("cases.RData")
## use_informative_priors <- TRUE
## results_bfg <- list()
## for(case_name in names(cases)) {
##   results_bfg[[ case_name ]] <- run_nimble_bfg(AFT_NH_Code, cases[[ case_name ]])
## }
## save(results_bfg, file = "results_bfg.RData")
## #debugonce(run_nimble_bfg)
## #test_res_bfg <- run_nimble_bfg(AFT_NH_Code, test_case)

## Generate results with valid initial values and slice samplers, still with the model as set up by BFG for NIMBLE and JAGS.
## ----eval=FALSE---------------------------------------------------------------
## load("cases.RData")
## use_informative_priors <- TRUE
## results_bfg_with_slice <- list()
## for(case_name in names(cases)) {
##   results_bfg_with_slice[[ case_name ]] <- run_nimble_bfg(AFT_NH_Code, cases[[ case_name ]], set_t_inits = TRUE, use_slice = TRUE)
## }
## save(results_bfg_with_slice, file = "results_bfg_with_slice.RData")
## #debugonce(run_nimble_bfg)
## #test_res_bfg_with_slice <- run_nimble_bfg(AFT_NH_Code, test_case, set_t_inits = TRUE)
## #test_res_bfg_with_slice_slice <- run_nimble_bfg(AFT_NH_Code, test_case, set_t_inits = TRUE, use_slice = TRUE)

## Set up the model in the same way it is given to Stan, with marginal calculations and matrix multiplication. 

## A difference is that this still uses the BUGS language parameterization of the Weibull distribution, which is different than the (shape, scale) parameterization used in Stan.  We don't think this should make a noticeable difference.  The priors are the same.

## ---- eval=FALSE--------------------------------------------------------------
## use_informative_priors <- TRUE
## AFT_NH_Code_marg <- nimbleCode({
##   #Likelihood
##   lambda_m[] <- log(2)*exp(-((X_m[,] %*% beta[])[,1])*alpha) #exp((X_m[,] %*% beta[])[,1])/pow(log(2), (1/alpha))
##   for(i in 1:N_m) {
##     zeros_m[i] ~ dpois( lambda_m[i]*pow(y_m[i], alpha) ) # zeros trick for complementary cumulative probability density of Weibull
##   }
##   lambda_o[] <- log(2)*exp(-((X_o[,] %*% beta[])[,1])*alpha)#exp((X_o[,] %*% beta[])[,1])/pow(log(2), (1/alpha))
##   for(i in 1:N_o) {
##     y_o[i] ~ dweib(shape = alpha, lambda_o[i])
##   }
## 
##   #Priors
##   if(use_informative_priors) {
##     for(i in 1:p){
##       beta[i] ~ dnorm(0,sd=sqrt(10))
##     }
##     alpha ~ dexp(1)
##   } else {
##     for(i in 1:p){
##       beta[i] ~ dnorm(0, var=1000)
##     }
##     alpha ~ dunif(0.01, 100)
##   }
## })

## Set up a function to run the marginal cases. 

## The data arrangement is taken from BFG's code to set up the problem for Stan.  The code to run and time NIMBLE is taken from BFG's code for that step in the previous cases

## ---- eval=FALSE--------------------------------------------------------------
## run_nimble_marg <- function(code, data, use_blocks = FALSE) {
##   attach(data)
##   on.exit(detach(data))
## 
##   censured=survt>cent
##   delta <- as.logical(1-censured)
##   survt[delta==0] <- cent[delta==0] # censor survival time.
## 
##   # count number of missing/censored survival times
##   n_miss <- N-sum(delta)
## 
##   # data for censored subjects
##   y_m=survt[delta==0]
##   X_m=X[delta==0,]
## 
##   # data for uncensored subjects
##   y_o=survt[delta==1]
##   X_o=X[delta==1,]
##   N_m = n_miss
##   N_o = N - n_miss
## 
##   beta0=rep(0.1, p)
##   alpha0=0.1
## 
##   aftConsts <- list(N_m=N_m,N_o=N_o,p=p)
##   aftInits <-  list(beta=beta0,alpha=alpha0)
##   aftData <- list(X_o=X_o, X_m = X_m, y_o = y_o, y_m = y_m, zeros_m = rep(0, N_m))
## 
##   t1<- system.time(
##     {
##       aftNH <- nimbleModel(code = code,dimensions = list(a = c(N,p), lambda_m = N_m, lambda_o = N_o),
##                            name = "aftNH",constants = aftConsts, data = aftData, inits = aftInits)
##       Caft <- compileNimble(aftNH)
##       aftConf <- configureMCMC(aftNH, print = TRUE)
##       if(use_blocks) {
##         aftConf$removeSamplers("beta")
##         aftConf$addSampler("beta", type = "RW_block", control = list(tries = p/2))
##       }
##       aftConf$addMonitors(c("beta","alpha"))
##       aftMCMC <- buildMCMC(aftConf)
##       CaftMCMC <- compileNimble(aftMCMC, project = aftNH)
##       t2<- system.time(
##         {
##           Psamples <- runMCMC(CaftMCMC, niter=(10000), nburnin=5000, thin=2,
##                               nchains=1,samplesAsCodaMCMC = TRUE,summary=TRUE)
##         })
##     })
##   list(t1 = t1, t2 = t2, Psamples = Psamples)
## }

## Run MCMC with the marginal implementation for all cases.

## ----eval=FALSE---------------------------------------------------------------
## load("cases.RData")
## use_informative_priors <- FALSE
## results_marg <- list()
## for(case_name in names(cases)) {
##   results_marg[[ case_name ]] <- run_nimble_marg(AFT_NH_Code_marg, cases[[case_name]], use_blocks = FALSE)
## }
## save(results_marg, file = "results_marg.RData")
## # debugonce(run_nimble_marg)
## # test_res_marg <- run_nimble_marg(AFT_NH_Code_marg, test_case, use_blocks = FALSE)

## Run MCMC with the marginal implementation and a block sampling experiment.

## ----eval=FALSE---------------------------------------------------------------
## load("cases.RData")
## use_informative_priors <- FALSE
## results_marg_blocks <- list()
## for(case_name in names(cases)) {
##   results_marg_blocks[[ case_name ]] <- run_nimble_marg(AFT_NH_Code_marg, cases[[case_name]], use_blocks = TRUE)
## }
## save(results_marg_blocks, file = "results_marg_blocks.RData")
## # test_res_marg_blocks <- run_nimble_marg(AFT_NH_Code_marg, test_case, use_blocks = TRUE)


## ---- echo=FALSE--------------------------------------------------------------
load("cases.RData")
load("results_bfg.RData")
load("results_bfg_with_slice.RData")
load("results_marg.RData")
load("results_marg_blocks.RData")

summarize_one_result <- function(result) {
  cols <- colnames(result$Psamples[[1]])
  beta_cols <- grepl("beta", cols)
  meanESS <- mean(coda::effectiveSize(result$Psamples[[1]][,beta_cols]))
  Ns <- nrow(result$Psamples[[1]]) # Number of saved samples
  Nit <- 4*Ns # In the settings of BFG, 50% are burn-in and thin = 2, so total number of iterations = 4 * number of saved samples
  c(ESS_per_Ns = meanESS/Ns, Nit_per_time = Nit/sum(result$t2[1:2]), meanESS_per_time = meanESS/sum(result$t2[1:2]))
}

all_results <- cbind(
  do.call('rbind', lapply(results_bfg, summarize_one_result)),
  do.call('rbind', lapply(results_bfg_with_slice, summarize_one_result)),
  do.call('rbind', lapply(results_marg, summarize_one_result)),
  do.call('rbind', lapply(results_marg_blocks, summarize_one_result))
)

colnames(all_results) <- rep( c("ESS/Ns", "Nit/t", "ESS/t"), 4)


## -----------------------------------------------------------------------------
library(kableExtra)
kbl(all_results, digits = 2) %>% 
  kable_classic() %>%
  add_header_above(c(" " = 1, "BFG (invalid)" = 3, "BFG+inits+slice" = 3, "Marginal" = 3, "Marginal+blocks" = 3)) %>%
  pack_rows("Perc = 0.2", 1, 4) %>%
  pack_rows("Perc = 0.5", 5, 8) %>%
  pack_rows("Perc = 0.8", 9, 12)

## This will open a browser page.  The html can be viewed as source, copied and pasted.
